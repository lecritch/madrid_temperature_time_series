{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Adventures - Challenge 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other Meetups\n",
    "- Machine Learning Paper Club (on meetup.com)\n",
    "- Bethesda Artificial Intelligence Meetup (on meetup.com)\n",
    "- Deep Learning and Data Science Partner Communities\n",
    "- hatchpad: start up and job opportunities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dimitri\n",
    "- imputing visibility - why mode?  if visibility was related to humidity, did they have a lienar relationship?  could you impute the visibility value with a value predicted by humidity? \n",
    "- doing linear regression - temperature is rising which you can see if you do LR on temperature \n",
    "- why MAE?\n",
    "- protect from data leakage -make sure train, val, test don't overlap\n",
    "    - quick way to diagnose you have data leakage:  multiply by 1mil (multiply the date you're trying to predict by 1mil), use inflated array and make sure your forecasts are note inflated - that way, if you get a prediction in the millions, you know instantly that you've had data leakage...\n",
    "- took last 3 years as a test period \n",
    "- 7 days had the best window for ridge regression - why is this though? \n",
    "- what's your 'configureation' about?  the (7, 1, 1)?\n",
    "- univariate analysis hitting a ceiling, so looking at multivariate solutions \n",
    "- used sequential LSTM - look up to LSTM - layer with 512 nodes, and 1 hidden dense layer with 16 nodes "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### George\n",
    "- focused on univariate models\n",
    "- used label encoder - why not one hot encode? - used it to change events to integers, wasn't really dummy it out \n",
    "- how is train test split affected by the fact that temperature averages are linearly increasing over time (as dimitri said? )\n",
    "- dnn = deep neural network\n",
    "- can add a lambda layer in keras models to apply instant function to outputs to scale them on the spot..?\n",
    "- don't do batch normalisation or dropout regularisation - he actually was talking about it in relation to normalisation not regularisation... \n",
    "- model 7 - prophet:  facebook data science software \n",
    "- future iterations - predict events "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Robert\n",
    "- Spoke about offsets - missed this bit - not sure what the aim with offsets was so look into this again - listen over the recording. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cap-env",
   "language": "python",
   "name": "cap-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
